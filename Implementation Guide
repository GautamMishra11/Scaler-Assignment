# Implementation Guide for Asana Simulation

## Overview

This guide will help you complete the implementation in the remaining time. I've provided you with:

1. âœ… Complete database schema (schema.sql)
2. âœ… ERD diagram (paste into dbdiagram.io)
3. âœ… Comprehensive methodology document
4. âœ… Project structure with main.py
5. âœ… Core utilities (database, logger, LLM wrapper)
6. âœ… Example generators (organization)

## What You Need to Complete

### Priority 1: Core Generators (2-3 hours)

These are essential and follow similar patterns:

#### 1. Teams Generator (`src/generators/teams.py`)
```python
class TeamGenerator:
    def generate(self) -> List[Dict]:
        # Create teams based on team_type distribution
        # Engineering: 40%, Product: 12%, Sales: 15%, etc.
        # Use realistic names per team type
        pass
    
    def assign_members(self, users):
        # Assign users to teams
        # 60% in 1 team, 30% in 2 teams, 10% in 3 teams
        pass
```

**Key Logic**:
- Total teams: ~60-100 (scale with employee count)
- Team sizes: 70% have 5-12 members, 20% have 13-25, 10% have 26-50
- Names: Use patterns from methodology doc

#### 2. Users Generator (`src/generators/users.py`)
```python
class UserGenerator:
    def generate(self) -> List[Dict]:
        # Generate target number of users
        # Use Faker library for names
        # Distribute roles: 85% member, 12% admin, etc.
        # Job titles match team types
        pass
```

**Key Logic**:
- Use `from faker import Faker` for realistic names
- Email: `first.last@domain.com`
- `created_at`: Spread over 24 months with hiring curve
- `last_active_at`: 90% within last 7 days

#### 3. Projects Generator (`src/generators/projects.py`)
```python
class ProjectGenerator:
    def generate(self) -> List[Dict]:
        # Create projects per team
        # ~6 projects per team
        # Generate sections per project
        pass
```

**Key Logic**:
- Project types: 35% ongoing, 30% sprint, 15% bug_tracking, etc.
- Section names vary by project_type (see methodology)
- 70% active, 20% completed, 8% archived, 2% on hold

#### 4. Tasks Generator (`src/generators/tasks.py`)
```python
class TaskGenerator:
    def __init__(self, db_manager, projects, users):
        self.llm = LLMGenerator()  # Use the LLM wrapper provided
    
    def generate(self) -> List[Dict]:
        # Most time-consuming generator
        # ~60K-120K tasks total
        # Use LLM for names and descriptions
        pass
    
    def _generate_task_name(self, project, section, team_type):
        # Use LLM with appropriate prompt
        prompt = self._get_name_prompt(project, team_type)
        return self.llm.generate(prompt)
```

**Key Logic**:
- Tasks per user: ~12 average (mix of completed and active)
- Completion rates vary by project type (see methodology)
- Use LLM in batches of 50-100 for efficiency
- Implement cycle time using log-normal distribution

### Priority 2: Activity Generators (1-2 hours)

#### 5. Comments Generator (`src/generators/comments.py`)
```python
class CommentGenerator:
    def generate(self) -> List[Dict]:
        # 40% of tasks get comments
        # Complex tasks get more comments
        # Use LLM for comment text
        pass
```

#### 6. Custom Fields Generator (`src/generators/custom_fields.py`)
```python
class CustomFieldGenerator:
    def generate(self):
        # Create field definitions per project
        # Engineering projects: ~5 fields (Priority, Status, Story Points, etc.)
        # Create enum options for enum type fields
        # Generate values for ~60% of tasks
        pass
```

#### 7. Stories Generator (`src/generators/stories.py`)
```python
class StoryGenerator:
    def generate(self) -> List[Dict]:
        # Create audit log entries for all task actions
        # created, completed, assigned, due_date_changed, etc.
        # Auto-generate text: "{user} completed this task"
        pass
```

### Priority 3: Scrapers (Optional - Can Use Hardcoded Data)

If time permits, implement these. Otherwise, use hardcoded lists:

#### `src/scrapers/yc_companies.py`
```python
def scrape_yc_companies():
    # Scrape Y Combinator company directory
    # Filter for B2B SaaS, >5K employees
    # Return: [{name, domain, industry}]
    pass
```

#### `src/scrapers/github_tasks.py`
```python
def scrape_github_issues():
    # Get task naming patterns from GitHub issues
    # Top 100 SaaS repos
    # Extract: issue titles, common formats
    pass
```

## Quick Implementation Strategy

### Time-Saving Approaches

1. **Start with Hardcoded Data**
   - Use the example lists in methodology
   - Implement scrapers only if time permits

2. **LLM Fallback**
   - I've provided fallback generation in `llm.py`
   - Works without API key using templates
   - Less realistic but functional

3. **Batch Processing**
   - Generate data in chunks
   - Commit to DB every 1000 records
   - Show progress bars with `tqdm`

4. **Parallel Testing**
   - Start with small dataset (500 employees)
   - Test end-to-end
   - Scale up once working

### Sample Test Run

```python
# In main.py Config class:
class Config:
    MIN_EMPLOYEES = 500  # Start small!
    MAX_EMPLOYEES = 1000
    PROJECTS_PER_TEAM = 3  # Reduce for testing
    TASKS_PER_USER = 5
```

This generates ~5K tasks (manageable in 5-10 minutes for testing).

## Code Templates

### Generator Base Class Pattern

```python
class BaseGenerator:
    def __init__(self, db_manager, *args):
        self.db = db_manager
        self.logger = logging.getLogger(self.__class__.__name__)
    
    def generate(self):
        raise NotImplementedError()
    
    def _generate_id(self):
        return str(uuid.uuid4())
    
    def _random_timestamp(self, start_date, end_date):
        # Helper for random timestamps
        pass
```

### Batch Insert Pattern

```python
def generate(self):
    items = []
    batch_size = 1000
    
    for i in range(total_count):
        item = self._create_item(i)
        items.append(item)
        
        # Insert in batches
        if len(items) >= batch_size:
            self.db.insert_many('table_name', items)
            items = []
            self.logger.info(f"Inserted {i+1}/{total_count}")
    
    # Insert remaining
    if items:
        self.db.insert_many('table_name', items)
    
    return all_items
```

### Date Generation Pattern

```python
from datetime import datetime, timedelta
import random

def random_business_day(start_date, end_date):
    """Generate random business day timestamp"""
    while True:
        # Random date in range
        days_between = (end_date - start_date).days
        random_days = random.randint(0, days_between)
        random_date = start_date + timedelta(days=random_days)
        
        # Check if business day (Mon-Fri)
        if random_date.weekday() < 5:  # 0=Mon, 6=Sun
            # Random time during business hours (9 AM - 6 PM)
            hour = random.randint(9, 17)
            minute = random.randint(0, 59)
            return random_date.replace(hour=hour, minute=minute, second=0)
```

## Validation Checklist

Before submission, verify:

- [ ] Database file generates successfully
- [ ] All tables have data (check via SQL queries)
- [ ] No orphaned records (foreign keys valid)
- [ ] Temporal consistency (created_at < completed_at)
- [ ] Completion rates match methodology (~75% for sprints)
- [ ] No users with >30 active tasks
- [ ] Database size: 50-150 MB (indicates realistic scale)
- [ ] Run time: <1 hour for full dataset

## SQL Validation Queries

Add these to your validation checks:

```sql
-- Check data exists in all tables
SELECT 
    'organizations' as table_name, COUNT(*) as count FROM organizations
UNION ALL SELECT 'teams', COUNT(*) FROM teams
UNION ALL SELECT 'users', COUNT(*) FROM users
-- ... etc for all tables

-- Verify task completion rates
SELECT 
    p.project_type,
    COUNT(*) as total_tasks,
    SUM(CASE WHEN t.completed THEN 1 ELSE 0 END) as completed,
    ROUND(100.0 * SUM(CASE WHEN t.completed THEN 1 ELSE 0 END) / COUNT(*), 1) as pct
FROM tasks t
JOIN projects p ON t.project_id = p.project_id
GROUP BY p.project_type;

-- Check for temporal violations
SELECT COUNT(*) as violations
FROM tasks
WHERE completed = 1 AND completed_at < created_at;

-- Check workload distribution
SELECT 
    MIN(task_count) as min_tasks,
    AVG(task_count) as avg_tasks,
    MAX(task_count) as max_tasks
FROM (
    SELECT assignee_id, COUNT(*) as task_count
    FROM tasks
    WHERE completed = 0 AND assignee_id IS NOT NULL
    GROUP BY assignee_id
);
```

## Documentation Tips

### Section B: Seed Data Methodology

For each generator you implement:

1. **Copy the table format** from my methodology document
2. **Fill in your actual implementation** details
3. **Cite sources** - even if using hardcoded data, cite where you got it
4. **Explain distributions** - show the math/research

Example:
```
Table: users

| Column | Data Type | Source | Methodology |
|--------|-----------|--------|-------------|
| name | TEXT | Faker Library | Generated using Faker's `name()` method with locale='en_US'. Names follow US Census distribution built into Faker (based on 2010 census data). |
```

### Common Pitfalls to Avoid

1. **Don't mention "placeholder data"** - Always describe it as derived/synthetic
2. **Always cite sources** - Even if it's "Faker library defaults to US Census 2010"
3. **Explain distributions** - Never just say "random" - say "uniform random between X and Y"
4. **Show calculations** - "70% of teams sized 5-12 (based on Dunbar's number research)"

## Time Management

**If you're running low on time:**

### Must-Have (3 hours):
- Organizations âœ“ (provided)
- Teams (30 min)
- Users (45 min)
- Projects (45 min)
- Tasks (1 hour - can reduce scale)

### Should-Have (1.5 hours):
- Comments (30 min)
- Custom Fields (30 min)
- Stories (30 min)

### Nice-to-Have (1.5 hours):
- Attachments (15 min)
- Tags (15 min)
- Task Dependencies (15 min)
- Scrapers (45 min)

## Final Submission Checklist

Before submitting:

1. **Test end-to-end**
   ```bash
   rm output/asana_simulation.sqlite
   python src/main.py
   ```

2. **Verify database**
   ```bash
   sqlite3 output/asana_simulation.sqlite
   .tables
   SELECT COUNT(*) FROM tasks;
   ```

3. **Check documentation**
   - [ ] Schema section complete
   - [ ] Methodology table for each entity
   - [ ] All distributions cited
   - [ ] ERD diagram included

4. **Code quality**
   - [ ] No TODO comments in submitted code
   - [ ] All functions have docstrings
   - [ ] README has clear setup instructions
   - [ ] requirements.txt is complete

5. **GitHub repo**
   - [ ] All code committed
   - [ ] README is comprehensive
   - [ ] .env.example included (not .env with real keys!)
   - [ ] Database file in output/ (check size <150MB for GitHub)

## Getting Help

If stuck:

1. **Reference the provided files** - They show the pattern
2. **Start simple** - Get basic version working, then add realism
3. **Use Faker library** - It handles names, dates, text automatically
4. **Check the methodology doc** - All distributions are documented

## Success Metrics

Your submission will stand out if:

- âœ… Database generates without errors
- âœ… Data looks realistic (real names, plausible task titles)
- âœ… All distributions match methodology
- âœ… Temporal consistency enforced
- âœ… Code is clean and well-commented
- âœ… Documentation is thorough with citations

Good luck! ğŸš€
